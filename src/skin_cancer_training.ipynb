{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724d61ec",
   "metadata": {},
   "source": [
    "# Skin Cancer Classification with ISIC ðŸ““"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462a914",
   "metadata": {},
   "source": [
    "\n",
    "Este notebook demonstra um *pipeline* completo para treinar um classificador de melanoma\n",
    "usando o **ISIC Archive** e os metadados jÃ¡ estratificados em `folds_13062020.csv`.\n",
    "\n",
    "### ConteÃºdo\n",
    "1. InstalaÃ§Ã£o de dependÃªncias  \n",
    "2. Carregamento do CSV e inspeÃ§Ã£o inicial  \n",
    "3. Download das imagens via API ISIC  \n",
    "4. *Dataset* PyTorch + **Albumentations**  \n",
    "5. Treino com 5 *folds* (EfficientNetâ€‘B3)  \n",
    "6. AvaliaÃ§Ã£o (ROCâ€‘AUC)  \n",
    "7. ExportaÃ§Ã£o (`TorchScript`) e inferÃªncia de exemplo  \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f52397ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:05:50.229108Z",
     "start_time": "2025-05-14T14:05:45.793809Z"
    }
   },
   "source": [
    "import pandas as pd, numpy as np, torch, timm, requests, time, os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm.auto import tqdm\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovanni/Documents/git/medicine/dermalert/dermalert-ml/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "ae381584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:05:55.596192Z",
     "start_time": "2025-05-14T14:05:55.507897Z"
    }
   },
   "source": [
    "CSV_PATH = 'metadata/folds_13062020.csv'\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df['image_id'] = [\"_\".join(x.split('_')[:-1 if len(x.split('_')) > 2 else 2]) for x in df['image_id']]\n",
    "print(df.head())\n",
    "print(\"\\nTarget distribution (0=benign, 1=melanoma):\")\n",
    "print(df['target'].value_counts())\n",
    "NUM_FOLDS = df['fold'].nunique()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id  patient_id  target  source     sex  age_approx  \\\n",
      "0  ISIC_2637011  IP_7279968       0  ISIC20    male        45.0   \n",
      "1  ISIC_0015719  IP_3075186       0  ISIC20  female        45.0   \n",
      "2  ISIC_0052212  IP_2842074       0  ISIC20  female        50.0   \n",
      "3  ISIC_0068279  IP_6890425       0  ISIC20  female        45.0   \n",
      "4  ISIC_0074268  IP_8723313       0  ISIC20  female        55.0   \n",
      "\n",
      "  anatom_site_general_challenge  stratify_group  fold  \n",
      "0                     head/neck              31     0  \n",
      "1               upper extremity               7     2  \n",
      "2               lower extremity               5     4  \n",
      "3                     head/neck               7     0  \n",
      "4               upper extremity               6     4  \n",
      "\n",
      "Target distribution (0=benign, 1=melanoma):\n",
      "target\n",
      "0    52302\n",
      "1     4922\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "5bacbbb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:21:59.556856Z",
     "start_time": "2025-05-14T14:21:59.542327Z"
    }
   },
   "source": [
    "API_URL = \"https://api.isic-archive.com/api/v2/images/{id}/\"\n",
    "CACHE_DIR = Path('images')\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def fetch_image(isic_id: str) -> Path:\n",
    "    \"\"\"Baixa a imagem via API ISIC (se ainda nÃ£o estiver em cache).\"\"\"\n",
    "    dest = CACHE_DIR / f\"{isic_id}.jpg\"\n",
    "    if dest.exists():\n",
    "        return dest\n",
    "    for _ in range(3):  # 3 tentativas\n",
    "        r = requests.get(API_URL.format(id=isic_id), timeout=30)\n",
    "        if r.ok:\n",
    "            path_download = r.json()['files']['full']['url']\n",
    "            r = requests.get(path_download, timeout=30)\n",
    "            dest.write_bytes(r.content)\n",
    "            return dest\n",
    "        time.sleep(2)\n",
    "    raise RuntimeError(f'Falha ao baixar {isic_id}')\n",
    "\n",
    "# Total de imagens ja baixadas:\n",
    "print(\"Total de imagens jÃ¡ baixadas:\", len(list(CACHE_DIR.glob('*'))))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens jÃ¡ baixadas: 1543\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "946a8258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:06:01.250105Z",
     "start_time": "2025-05-14T14:06:01.237133Z"
    }
   },
   "source": [
    "mean, std = [0.5]*3, [0.5]*3\n",
    "train_tfms = A.Compose([\n",
    "    A.LongestMaxSize(512),\n",
    "    A.PadIfNeeded(512, 512),\n",
    "    A.RandomRotate90(),\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=1),\n",
    "        A.VerticalFlip(p=1),\n",
    "    ], p=0.5),\n",
    "    A.RandomBrightnessContrast(0.2, 0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05,\n",
    "                       scale_limit=0.1,\n",
    "                       rotate_limit=20,\n",
    "                       border_mode=0),\n",
    "    A.Normalize(mean, std),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "val_tfms = A.Compose([\n",
    "    A.LongestMaxSize(512), A.PadIfNeeded(512, 512),\n",
    "    A.Normalize(mean, std), ToTensorV2()\n",
    "])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovanni/Documents/git/medicine/dermalert/dermalert-ml/.venv/lib/python3.13/site-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "8a943f1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:06:04.697886Z",
     "start_time": "2025-05-14T14:06:04.694418Z"
    }
   },
   "source": [
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        import numpy as np\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transforms = transforms\n",
    "        self.np = np\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = fetch_image(row.image_id)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transforms(image=self.np.array(img))['image']\n",
    "        label = torch.tensor(row.target).long()\n",
    "        return img, label\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "4078b7b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:06:08.557699Z",
     "start_time": "2025-05-14T14:06:08.552233Z"
    }
   },
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for x, y in tqdm(dataloader, leave=False):\n",
    "        x, y = x.to(device), y.float().unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds, gts = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            preds.extend(torch.sigmoid(logits).cpu().numpy().ravel())\n",
    "            gts.extend(y.numpy())\n",
    "    return roc_auc_score(gts, preds)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "4830259c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:20:55.585825Z",
     "start_time": "2025-05-14T14:06:18.447962Z"
    }
   },
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EPOCHS = 10\n",
    "BATCH = 16\n",
    "scores = []\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    print(f\"\\n===== Fold {fold}/{NUM_FOLDS-1} =====\")\n",
    "    tr_df = df[df.fold != fold]\n",
    "    vl_df = df[df.fold == fold]\n",
    "    \n",
    "    train_ds = ISICDataset(tr_df, train_tfms)\n",
    "    val_ds   = ISICDataset(vl_df, val_tfms)\n",
    "    dl_tr = DataLoader(train_ds, BATCH, shuffle=True, num_workers=os.cpu_count()//2 or 2)\n",
    "    dl_vl = DataLoader(val_ds, BATCH*2, shuffle=False, num_workers=os.cpu_count()//2 or 2)\n",
    "    \n",
    "    model = timm.create_model('efficientnet_b3a', pretrained=True, num_classes=1).to(device)\n",
    "    \n",
    "    pos_weight = (tr_df.target==0).sum() / (tr_df.target==1).sum()\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    best_auc, best_state = 0, None\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss = train_one_epoch(model, dl_tr, optimizer, criterion, device)\n",
    "        auc  = evaluate(model, dl_vl, device)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} â€“ loss {loss:.4f} â€“ val AUC {auc:.4f}\")\n",
    "        if auc > best_auc:\n",
    "            best_auc, best_state = auc, model.state_dict()\n",
    "    \n",
    "    torch.save(best_state, f\"model_fold{fold}.pt\")\n",
    "    scores.append(best_auc)\n",
    "    print(f\"Fold {fold} best AUC: {best_auc:.4f}\")\n",
    "    \n",
    "print(\"\\nMÃ©dia AUC dos folds:\", np.mean(scores))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 0/4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovanni/Documents/git/medicine/dermalert/dermalert-ml/.venv/lib/python3.13/site-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name efficientnet_b3a to current efficientnet_b3.\n",
      "  model = create_fn(\n",
      "                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     22\u001B[39m best_auc, best_state = \u001B[32m0\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(EPOCHS):\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m     loss = \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdl_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     25\u001B[39m     auc  = evaluate(model, dl_vl, device)\n\u001B[32m     26\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mEPOCHS\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m â€“ loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m â€“ val AUC \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mauc\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 9\u001B[39m, in \u001B[36mtrain_one_epoch\u001B[39m\u001B[34m(model, dataloader, optimizer, criterion, device)\u001B[39m\n\u001B[32m      7\u001B[39m logits = model(x)\n\u001B[32m      8\u001B[39m loss = criterion(logits, y)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m optimizer.step()\n\u001B[32m     11\u001B[39m losses.append(loss.item())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/git/medicine/dermalert/dermalert-ml/.venv/lib/python3.13/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/git/medicine/dermalert/dermalert-ml/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/git/medicine/dermalert/dermalert-ml/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a843703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o melhor modelo (ajuste o fold se quiser outro)\n",
    "model = timm.create_model('efficientnet_b3a', pretrained=False, num_classes=1)\n",
    "model.load_state_dict(torch.load('model_fold0.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "scripted = torch.jit.script(model)\n",
    "scripted.save('skin_risk_classifier.pt')\n",
    "print(\"Modelo exportado em skin_risk_classifier.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DemonstraÃ§Ã£o de inferÃªncia\n",
    "sample_id = df.iloc[0].image_id\n",
    "img_path = fetch_image(sample_id)\n",
    "from IPython.display import display\n",
    "display(Image.open(img_path).resize((256,256)))\n",
    "\n",
    "proc = val_tfms(image=np.array(Image.open(img_path)))['image'].unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    prob = torch.sigmoid(model(proc))[0,0].item()\n",
    "print(f\"Probabilidade de melanoma para {sample_id}: {prob:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
